# FlashScore Site Implementation ðŸ€âš½

> **The FlashScore scraper is a reference implementation built on the Scrapamoja framework.** It demonstrates how to build a production-grade site scraper with sport-aware extraction, status-based flows, and hierarchical YAML selectors.

---

## What It Scrapes

FlashScore is a live sports data aggregator. This implementation extracts:

- **Match lists** â€” scheduled, live, and finished matches per sport
- **Match summaries** â€” teams, scores, competition, and timing
- **Match stats** â€” in-game statistics per tab context (summary, stats, odds, H2H)
- **Match odds** â€” betting odds where available
- **Head-to-head history** â€” past results between two teams

**Supported sports:** Basketball, Football
**Supported statuses:** Live, Finished, Scheduled

---

## Structure

```
flashscore/
â”œâ”€â”€ scraper.py              # FlashscoreScraper â€” main scraper class
â”œâ”€â”€ flow.py                 # FlashscoreFlow â€” page navigation logic
â”œâ”€â”€ orchestrator.py         # Orchestrates full scrape sessions
â”œâ”€â”€ config.py               # Site config (ID, base URL, sport definitions)
â”œâ”€â”€ selector_config.py      # Selector configuration loader
â”œâ”€â”€ extractors/             # Status-specific data extractors
â”‚   â”œâ”€â”€ base_extractor.py
â”‚   â”œâ”€â”€ live_match_extractor.py
â”‚   â”œâ”€â”€ finished_match_extractor.py
â”‚   â”œâ”€â”€ scheduled_match_extractor.py
â”‚   â”œâ”€â”€ basketball_match_detail_extractor.py
â”‚   â”œâ”€â”€ basketball_tertiary_extractor.py
â”‚   â”œâ”€â”€ match_detail_extractor.py
â”‚   â”œâ”€â”€ primary_tab_extractor.py
â”‚   â””â”€â”€ tertiary_tab_extractor.py
â”œâ”€â”€ selectors/              # YAML selector definitions
â”‚   â”œâ”€â”€ authentication/     # Cookie consent handling
â”‚   â”œâ”€â”€ extraction/         # Data extraction selectors
â”‚   â”‚   â”œâ”€â”€ match_list/     # Match listing page selectors
â”‚   â”‚   â”œâ”€â”€ match_summary/  # Summary tab (teams, score, time)
â”‚   â”‚   â”œâ”€â”€ match_stats/    # Stats tab
â”‚   â”‚   â”œâ”€â”€ match_odds/     # Odds tab
â”‚   â”‚   â””â”€â”€ match_h2h/      # Head-to-head tab
â”‚   â”œâ”€â”€ filtering/          # Competition and date filter controls
â”‚   â”‚   â”œâ”€â”€ competition_filter/
â”‚   â”‚   â””â”€â”€ date_filter/
â”‚   â””â”€â”€ navigation/         # Page navigation elements
â”‚       â”œâ”€â”€ primary_tabs/
â”‚       â”œâ”€â”€ secondary_tabs/
â”‚       â”œâ”€â”€ tertiary_tabs/
â”‚       â”œâ”€â”€ sport_selection/
â”‚       â”œâ”€â”€ match_navigation/
â”‚       â””â”€â”€ event_filter/
â”œâ”€â”€ models/                 # Data models for extracted content
â”œâ”€â”€ html_structure/         # Captured HTML snapshots (for selector dev)
â””â”€â”€ cli/                    # Command-line interface
    â””â”€â”€ commands/
        â”œâ”€â”€ scrape.py
        â””â”€â”€ validate.py
```

---

## How It Works

### Navigation Flow

The `FlashscoreFlow` class handles all page navigation:

```
Homepage â†’ Sport selection â†’ Status filter (live/finished/scheduled)
         â†’ Match list â†’ Match detail page â†’ Tab navigation (summary/stats/odds/h2h)
```

### Selector Hierarchy

Selectors are resolved from most specific to most generic:

```
sport â†’ status â†’ context â†’ element

Example: basketball â†’ live â†’ match_summary â†’ home_team
```

Each element can have multiple strategies (CSS, XPath) with weights â€” the engine picks the highest-confidence match and falls back automatically.

### Extractor Architecture

Each match status has a dedicated extractor class that knows what data is available for that state:

- `LiveMatchExtractor` â€” score, current period, elapsed time
- `FinishedMatchExtractor` â€” final score, period breakdown
- `ScheduledMatchExtractor` â€” kickoff time, competition, venue

Basketball has additional extractors for tertiary tab data (quarter-by-quarter breakdowns).

### Snapshot Integration

When a selector fails, the scraper automatically captures a full snapshot â€” HTML, screenshot, and selector trace â€” correlated by session ID. Snapshots are stored via `SnapshotManager` and can be used to update YAML selectors without re-running a live scrape.

---

## Usage

```bash
# From the project root using the unified CLI
python -m src.main flashscore scrape basketball live --limit 10
python -m src.main flashscore scrape football finished -o csv -f results.csv
python -m src.main flashscore scrape basketball scheduled --no-headless --verbose

# Or using the site CLI directly
python -m src.sites.flashscore.cli.main scrape basketball live --limit 5
```

**Output formats:** `json` (default), `csv`, `xml`

---

## Selector Configuration

Selectors live in `selectors/` as YAML files. Example:

```yaml
# selectors/extraction/match_summary/basketball/home_team.yaml
description: "Home team name"
confidence_threshold: 0.8
timeout: 3.0
retry_count: 2
strategies:
  - type: "css"
    selector: ".participant__home .participant__participantName"
    weight: 1.0
  - type: "css"
    selector: ".home-team-name"
    weight: 0.9
  - type: "xpath"
    selector: "//div[@class='participant__home']//div[@class='participant__participantName']"
    weight: 0.8
metadata:
  wait_for_element: true
  tab_context: "summary"
```

When FlashScore updates their HTML, update the selector YAML â€” no Python changes needed.

---

## Extending

**Add a new sport:**
1. Add sport definition to `config.py`
2. Create selector subdirectories under `selectors/extraction/match_summary/<sport>/`
3. Add a sport-specific extractor if the data shape differs significantly

**Add a new data type (e.g. lineups):**
1. Add selectors under `selectors/extraction/match_lineups/`
2. Create an extractor class inheriting from `BaseExtractor`
3. Wire it into the orchestrator

---

## Troubleshooting

**Selectors failing after a FlashScore update:**
Run with `--no-headless --verbose` to see the browser live, capture the new HTML structure, and update the relevant YAML file.

**No matches returned:**
Verify the sport/status combination has active data on FlashScore at the time of scraping. Scheduled matches only appear within a certain time window.

**Timeout errors:**
Increase `browser.timeout` in your config, or reduce `--limit` to scrape fewer matches per session.
